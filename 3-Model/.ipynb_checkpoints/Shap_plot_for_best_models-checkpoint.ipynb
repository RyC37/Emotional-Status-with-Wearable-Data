{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The least populated class in y has only 3 members, which is less than n_splits=4.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import catboost\n",
    "from evaluation_tools import eval_class, eval_reg, get_feature_imp_plot, convert_reg_to_class, catboost_feature_importance\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import pdb\n",
    "\n",
    "# File for model\n",
    "# result = pd.DataFrame(columns=['model_id','problem_type', 'data_type', 'data_sample', 'user_type', 'param_index', 'accuracy', 'recall', 'precision', 'specificity', 'npv', 'f1', 'RMSE', 'r2'])\n",
    "# result.to_csv('model_evaluation.csv', index=False)\n",
    "\n",
    "fitbit_features = ['step_max', 'step_min', 'step_median', 'steps_max_3h',\n",
    "    'steps_min_3h', 'steps_mean_3h', 'steps_var_3h', 'steps_median_3h',\n",
    "    'move_rate_3h', 'active_rate_3h', 'very_active_rate_3h',\n",
    "    'running_rate_3h', 'steps_max_1h', 'steps_min_1h', 'steps_mean_1h',\n",
    "    'steps_var_1h', 'steps_median_1h', 'move_rate_1h',\n",
    "    'active_rate_1h', 'very_active_rate_1h', 'running_rate_1h',\n",
    "    'steps_max_30m', 'steps_min_30m', 'steps_mean_30m',\n",
    "    'steps_var_30m', 'steps_median_30m', 'move_rate_30m',\n",
    "    'active_rate_30m', 'very_active_rate_30m', 'running_rate_30m',\n",
    "    'steps_max_10m', 'steps_min_10m', 'steps_mean_10m',\n",
    "    'steps_var_10m', 'steps_median_10m', 'move_rate_10m',\n",
    "    'active_rate_10m', 'very_active_rate_10m', 'running_rate_10m',\n",
    "    'steps_max_5m', 'steps_min_5m', 'steps_mean_5m', 'steps_var_5m',\n",
    "    'steps_median_5m', 'move_rate_5m', 'active_rate_5m',\n",
    "    'very_active_rate_5m', 'running_rate_5m', 'hr_max', 'hr_min',\n",
    "    'hr_med', 'hr_0', 'hr_0.3', 'hr_0.5', 'hr_0.8', 'hr_1', 'SDNN_3h',\n",
    "    'pHR2_3h', 'rMSSD_3h', 'low_hr_3h', 'high_hr_3h', 'l_h_3h',\n",
    "    'CR_3h', 'hr_mean_3h', 'hr_var_3h', 'hr_std_3h', 'hr_median_3h',\n",
    "    'hr_rest_rate_3h', 'hr_moderate_rate_3h', 'hr_very_active_rate_3h',\n",
    "    'SDNN_1h', 'pHR2_1h', 'rMSSD_1h', 'low_hr_1h', 'high_hr_1h',\n",
    "    'l_h_1h', 'CR_1h', 'hr_mean_1h', 'hr_var_1h', 'hr_std_1h',\n",
    "    'hr_median_1h', 'hr_rest_rate_1h', 'hr_moderate_rate_1h',\n",
    "    'hr_very_active_rate_1h', 'SDNN_30m', 'pHR2_30m', 'rMSSD_30m',\n",
    "    'low_hr_30m', 'high_hr_30m', 'l_h_30m', 'CR_30m', 'hr_mean_30m',\n",
    "    'hr_var_30m', 'hr_std_30m', 'hr_median_30m', 'hr_rest_rate_30m',\n",
    "    'hr_moderate_rate_30m', 'hr_very_active_rate_30m', 'SDNN_10m',\n",
    "    'pHR2_10m', 'rMSSD_10m', 'low_hr_10m', 'high_hr_10m', 'l_h_10m',\n",
    "    'CR_10m', 'hr_mean_10m', 'hr_var_10m', 'hr_std_10m',\n",
    "    'hr_median_10m', 'hr_rest_rate_10m', 'hr_moderate_rate_10m',\n",
    "    'hr_very_active_rate_10m', 'SDNN_5m', 'pHR2_5m', 'rMSSD_5m',\n",
    "    'low_hr_5m', 'high_hr_5m', 'l_h_5m', 'CR_5m', 'hr_mean_5m',\n",
    "    'hr_var_5m', 'hr_std_5m', 'hr_median_5m', 'hr_rest_rate_5m',\n",
    "    'hr_moderate_rate_5m', 'hr_very_active_rate_5m']\n",
    "\n",
    "all_features = fitbit_features + ['SBQ', 'FTP', 'SWLS', 'Neuroticism', \n",
    "    'Extraversion', 'Conscientiousness', 'NS_total', 'BIS_total', \n",
    "    'BIS.5', 'BAS_D', 'BAS_FS', 'BAS_RR', 'HAP_actual', 'P_actual', \n",
    "    'LAP_actual', 'LA_actual', 'LAN_actual', 'N_actual', 'HAN_actual', \n",
    "    'HA_actual', 'HAP_ideal', 'P_ideal', 'LAP_ideal', 'LA_ideal', \n",
    "    'LAN_ideal', 'N_ideal', 'HAN_ideal', 'HA_ideal', 'Children', 'Age', \n",
    "    'BMI', 'survey_hour', 'r2r_corr', 'Corr_z', 'edu_hs', \n",
    "    'edu_ba', 'edu_ma', 'edu_phd', 'is_married', 'is_divorced', \n",
    "    'is_single', 'is_widowed', 'is_with_partner', 'income']\n",
    "\n",
    "\n",
    "# Existing Users\n",
    "X_stratified_val = pd.read_csv('../data/processed/cur_user/X_val_stratify.csv')\n",
    "y_stratified_val = pd.read_csv('../data/processed/cur_user/y_val_stratify.csv')\n",
    "X_stratified_test = pd.read_csv('../data/processed/cur_user/X_test_stratify.csv')\n",
    "y_stratified_test = pd.read_csv('../data/processed/cur_user/y_test_stratify.csv')\n",
    "X_stratified_train = pd.read_csv('../data/processed/cur_user/X_train_stratify.csv')\n",
    "y_stratified_train = pd.read_csv('../data/processed/cur_user/y_train_stratify.csv')\n",
    "X_stratified_up_train = pd.read_csv('../data/processed/cur_user/X_train_stratify_up.csv')\n",
    "y_stratified_up_train = pd.read_csv('../data/processed/cur_user/y_train_stratify_up.csv')\n",
    "\n",
    "\n",
    "# New Users\n",
    "X_group_val = pd.read_csv('../data/processed/new_user/X_val_group.csv')\n",
    "y_group_val = pd.read_csv('../data/processed/new_user/y_val_group.csv')\n",
    "X_group_test = pd.read_csv('../data/processed/new_user/X_test_group.csv')\n",
    "y_group_test = pd.read_csv('../data/processed/new_user/y_test_group.csv')\n",
    "X_group_train = pd.read_csv('../data/processed/new_user/X_train_group.csv')\n",
    "y_group_train = pd.read_csv('../data/processed/new_user/y_train_group.csv')\n",
    "X_group_up_train = pd.read_csv('../data/processed/new_user/X_train_group_up.csv')\n",
    "y_group_up_train = pd.read_csv('../data/processed/new_user/y_train_group_up.csv')\n",
    "\n",
    "\n",
    "param1 = {\n",
    "    'verbose': 10,\n",
    "    'random_seed': 24,\n",
    "    'depth':10, \n",
    "    'learning_rate':0.001,\n",
    "    'use_best_model': True,\n",
    "    'l2_leaf_reg': 10,\n",
    "    'bagging_temperature': 3,\n",
    "    'od_type': \"Iter\",\n",
    "    'od_wait': 100\n",
    "}\n",
    "params = [param1]\n",
    "\n",
    "\n",
    "def upsample_data(X, y):\n",
    "    # concatenate our training data back together\n",
    "    data_to_sample = pd.concat([X, y], axis=1)\n",
    "    # separate minority and majority classes\n",
    "    unhappy = data_to_sample[data_to_sample['valence']==1]\n",
    "    happy = data_to_sample[data_to_sample['valence']==0]\n",
    "\n",
    "    # upsample minority\n",
    "    unhappy_upsampled = resample(unhappy,\n",
    "                        replace=True, # sample with replacement\n",
    "                        n_samples=len(happy), # match number in majority class\n",
    "                        random_state=27) # reproducible results\n",
    "\n",
    "    # combine majority and upsampled minority\n",
    "    upsampled = pd.concat([happy, unhappy_upsampled])\n",
    "\n",
    "    # Split train and test\n",
    "    y_upsample = upsampled['valence']\n",
    "    X_upsample = upsampled.drop('valence', axis=1)\n",
    "\n",
    "    return X_upsample, y_upsample\n",
    "\n",
    "\n",
    "def data_process(data_sample, X_train, y_train, param):\n",
    "    if data_sample == 'up':\n",
    "        X_train, y_train = upsample_data(X_train, y_train)\n",
    "    elif data_sample == 'weight':\n",
    "        class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "        param['class_weights'] = list(class_weights)\n",
    "    elif data_sample == 'smote':\n",
    "        sm = SMOTE(random_state=27, k_neighbors = 10, sampling_strategy=1.0)\n",
    "        X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "    elif data_sample == 'no':\n",
    "        pass\n",
    "    else:   \n",
    "        raise ValueError('Invalid value for <data_sample>')\n",
    "    return X_train, y_train, param\n",
    "\n",
    "\n",
    "def main(problem_type, data_type, data_sample, user_type, param_index):\n",
    "    param = params[param_index] # Hyper params\n",
    "    results = []\n",
    "\n",
    "    if user_type == 'new':\n",
    "        X_train = X_group_train\n",
    "        y_train = y_group_train\n",
    "        X_test = X_group_test\n",
    "        y_test = y_group_test\n",
    "        X_val = X_group_val\n",
    "        y_val = y_group_val\n",
    "    elif user_type == 'cur':\n",
    "        X_train = X_stratified_train\n",
    "        y_train = y_stratified_train\n",
    "        X_test = X_stratified_test\n",
    "        y_test = y_stratified_test\n",
    "        X_val = X_stratified_val\n",
    "        y_val = y_stratified_val\n",
    "    else:\n",
    "        raise ValueError('Invalid value for <user_type>')\n",
    "\n",
    "    if data_type == 'fitbit':\n",
    "        X_train = X_train[fitbit_features]\n",
    "        X_test = X_test[fitbit_features]\n",
    "        X_val = X_val[fitbit_features]\n",
    "    elif data_type == 'all':\n",
    "        X_train = X_train[all_features]\n",
    "        X_test = X_test[all_features]\n",
    "        X_val = X_val[all_features]\n",
    "    else:   \n",
    "        raise ValueError('Invalid value for <data_type>')\n",
    "\n",
    "    if problem_type == 'cls':\n",
    "        param['loss_function'] = 'Logloss'\n",
    "        param['eval_metric'] = 'F1'\n",
    "        X = pd.concat([X_train, X_test])\n",
    "        y = pd.concat([y_train, y_test])\n",
    "        group = y['subject'].values\n",
    "        # Split K Fold\n",
    "        if user_type == 'new':\n",
    "            kfold = GroupKFold(n_splits=4).split(X,y,group)\n",
    "        elif user_type == 'cur':\n",
    "            kfold = StratifiedKFold(n_splits=4, random_state=27, shuffle=True).split(X, group)\n",
    "        # Training\n",
    "        for train_index, test_index in kfold:\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            y_train = y_train['valence']\n",
    "            y_test = y_test['valence']\n",
    "            # pdb.set_trace()\n",
    "            # Data Sampling\n",
    "            X_train, y_train, param = data_process(data_sample, X_train, y_train, param)\n",
    "            # CatBoost\n",
    "            cat = catboost.CatBoostClassifier(**param)\n",
    "            cat.fit(X_train, y_train,\n",
    "                     eval_set = (X_test, y_test),\n",
    "                     use_best_model = True,\n",
    "                     verbose = False)\n",
    "            y_pred = cat.predict(X_val)\n",
    "            # pdb.set_trace()\n",
    "            cat_res = eval_class(y_val['valence'], y_pred)\n",
    "            results.append(cat_res +[0,0])\n",
    "            get_feature_imp_plot(cat, \"ShapValues\", X_train, y_train, X_test, y_test, [])\n",
    "            # feature_col = X_val.columns.values\n",
    "            # fi_score = catboost_feature_importance(cat, feature_col)\n",
    "            # fi_score.to_csv()\n",
    "    \n",
    "    elif problem_type == 'reg':\n",
    "        param.pop('class_weights', None)\n",
    "        param['loss_function'] = 'RMSE'\n",
    "        param['eval_metric'] = 'RMSE'\n",
    "        X = pd.concat([X_train, X_test])\n",
    "        y = pd.concat([y_train, y_test])\n",
    "        group = y['subject'].values\n",
    "        # Split K Fold\n",
    "        if user_type == 'new':\n",
    "            kfold = GroupKFold(n_splits=4).split(X,y,group)\n",
    "        elif user_type == 'cur':\n",
    "            kfold = StratifiedKFold(n_splits=4, random_state=27, shuffle=True).split(X, group)\n",
    "        # Training\n",
    "        for train_index, test_index in kfold:\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            # Two model, one for positive valence, one for negative valence\n",
    "            y_p_train = y_train['max_p']\n",
    "            y_p_test = y_test['max_p']\n",
    "            y_n_train = y_train['max_n']\n",
    "            y_n_test = y_test['max_n']\n",
    "            # Regression problem no data sampling technique\n",
    "            # CatBoost\n",
    "            model_p = catboost.CatBoostRegressor(**param)\n",
    "            model_p.fit(X_train, y_train['max_p'],\n",
    "                        eval_set = (X_test, y_test['max_p']),\n",
    "                        use_best_model = True,\n",
    "                        verbose = False)\n",
    "            p_regr = model_p.predict(X_val)\n",
    "\n",
    "            model_n = catboost.CatBoostRegressor(**param)\n",
    "            model_n.fit(X_train, y_train['max_n'],\n",
    "                        eval_set = (X_test, y_test['max_n']),\n",
    "                        use_best_model = True,\n",
    "                        verbose = False)\n",
    "            n_regr = model_n.predict(X_val)\n",
    "\n",
    "            y_pred = p_regr - n_regr\n",
    "            y_reg = y_val['max_p'] - y_val['max_n']\n",
    "            # print(model_regr)\n",
    "            y_pred_cls = convert_reg_to_class(y_pred)\n",
    "            y_reg_cls = convert_reg_to_class(y_reg)\n",
    "            # pdb.set_trace()\n",
    "            cat_res = eval_class(y_reg_cls, y_pred_cls)\n",
    "            reg_eval = eval_reg(y_reg, y_pred)\n",
    "            results.append(cat_res + reg_eval)\n",
    "\n",
    "    results = np.mean(results, axis=0)\n",
    "    training_params = [problem_type, data_type, data_sample, user_type, param_index]\n",
    "    return np.append(training_params, results), cat\n",
    "\n",
    "\n",
    "res = main('cls', 'all', 'weight', 'cur', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature_imp_plot(cat_rs_2, \"ShapValues\", X_stratified_train, y_stratified_train, X_stratified_val, y_stratified_val, categorical_features_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
