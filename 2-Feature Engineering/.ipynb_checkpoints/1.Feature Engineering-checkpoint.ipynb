{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Emotional Status Project\n",
    "Author: Sicong Zhao\n",
    "\n",
    "## 1.Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import datetime\n",
    "from tqdm import tqdm # Show pandas progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experience Sampling data, which contains 8 metrics labels for emotion states.\n",
    "# We are using these 8 metrics to generate the positive or negative of the emotion, and make the prediction.\n",
    "with open('data/EXPERIENCING_SAMPLE_R00_DND.pickle', 'rb') as handle:\n",
    "    exp = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Predictor: Steps, by minute, from Fitbit\n",
    "# with open('data/STEPS_R00_DND.pickle', 'rb') as handle:\n",
    "#     steps = pickle.load(handle)\n",
    "steps = pd.read_csv('steps_with_datetime.csv')\n",
    "steps['datetime'] = pd.to_datetime(steps['datetime'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (3,5,6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Predictor: Heart Rate, by minute, from Fitbit\n",
    "# with open('data/HR_R00_DND.pickle', 'rb') as handle:\n",
    "#     hr = pickle.load(handle)\n",
    "hr = pd.read_csv('hr_with_datetime.csv')\n",
    "hr['datetime'] = pd.to_datetime(hr['datetime'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor: Sleep, by day, from Fitbit\n",
    "with open('data/SLEEP_R00_DND.pickle', 'rb') as handle:\n",
    "    sleep = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicor: Survey, contains demographic, health, personality data, one time measurement for each subject.\n",
    "with open('data/SURVEY_R00_DND.pickle', 'rb') as handle:\n",
    "    survey = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                          0.772152\n",
       "Subject                        0.000000\n",
       "Actually Feel: Enthusiastic    0.772152\n",
       "Actual HAP                     0.772152\n",
       "Actually Feel: Dull            0.772152\n",
       "                                 ...   \n",
       "LAN_ideal                      0.297468\n",
       "N_ideal                        0.297468\n",
       "HAN_ideal                      0.297468\n",
       "HA_ideal                       0.297468\n",
       "Experiment                     0.000000\n",
       "Length: 139, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A lot of missing data in survey\n",
    "survey['AVI'].isna().sum() / survey['AVI'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Convert ID to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps['ID'] = steps['ID'].astype('str')\n",
    "sleep['ID'] = sleep['ID'].astype('str')\n",
    "hr['ID'] = hr['ID'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Add timestamp for heart rate, step data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hr['datetime'] = hr['Date'].astype(str) + ' ' + hr['TIME'].astype(str)\n",
    "# hr['datetime'] = pd.to_datetime(hr['datetime'], errors='coerce')\n",
    "# hr.to_csv('hr_with_datetime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps['datetime'] = steps['Date'].astype(str) + ' ' + steps['TIME'].astype(str)\n",
    "# steps['datetime'] = pd.to_datetime(steps['datetime'], errors='coerce')\n",
    "# steps.to_csv('steps_with_datetime.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Extract useful features and merge survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DEMOGRAPHICS', 'MEDICAL_SCREENING', 'AVI', 'BISBAS', 'BIS', 'TPQ_NS', 'NEO_SF', 'SWLS', 'FTP', 'SBQ'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns for Medical Screening\n",
    "med_df = survey['MEDICAL_SCREENING'][['Subject','BMI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns for SBQ\n",
    "sbq_df = survey['SBQ'][['Subject', 'SBQ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns for FTP\n",
    "ftp_df = survey['FTP'][['Subject', 'FTP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns for SWLS\n",
    "swls_df = survey['SWLS'][['Subject', 'SWLS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns for NEO-SF\n",
    "neosf_df = survey['NEO_SF'][['Subject', 'Neuroticism', 'Extraversion', 'Openness', 'Agreeableness','Conscientiousness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns for TPQ-NS\n",
    "tpqns_df = survey['TPQ_NS'][['Subject','NS_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns for BIS\n",
    "bis_df = survey['BIS'][['Subject','BIS_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns for BISBAS\n",
    "bisbas_cols = ['Subject', 'BIS.5', 'BAS_D', 'BAS_FS', 'BAS_RR']\n",
    "bisbas_df = survey['BISBAS'][bisbas_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Get columns for AVI\n",
    "avi_col_actual = [x for x in survey['AVI'].columns.values if 'actual' in x]\n",
    "avi_col_ideal = [x for x in survey['AVI'].columns.values if 'ideal' in x]\n",
    "avi_col = np.concatenate([['Subject'], avi_col_actual,avi_col_ideal])\n",
    "avi_df = survey['AVI'][avi_col]\n",
    "avi_df['Subject'] = avi_df['Subject'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns for Demographics\n",
    "demo_df = survey['DEMOGRAPHICS'][['Subject', 'Education', 'Ethnicity', 'Sex', 'Marital_Status', 'Children', 'Household_income', 'Religion', 'Age', 'Medications']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Merge all dataframes, which contains the features for modeling\n",
    "data_frames = [sbq_df, ftp_df, swls_df, neosf_df, tpqns_df, bis_df, bisbas_df, avi_df, demo_df, med_df]\n",
    "for df in data_frames:\n",
    "    df['Subject'] = df['Subject'].astype(str)\n",
    "\n",
    "survey_df = reduce(lambda  left,right: pd.merge(left,right,on=['Subject'],\n",
    "                                            how='left'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data type\n",
    "survey_df['Ethnicity'] = survey_df['Ethnicity'].astype(str, errors = 'raise')\n",
    "survey_df['Sex'] = survey_df['Sex'].astype(str, errors = 'raise')\n",
    "survey_df['Marital_Status'] = survey_df['Marital_Status'].astype(str, errors = 'raise')\n",
    "survey_df['Household_income'] = survey_df['Household_income'].astype(str, errors = 'raise')\n",
    "survey_df['Religion'] = survey_df['Religion'].astype(str, errors = 'raise')\n",
    "survey_df['Medications'] = survey_df['Medications'].astype(str, errors = 'raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject              0.000000\n",
       "SBQ                  0.000000\n",
       "FTP                  0.297468\n",
       "SWLS                 0.297468\n",
       "Neuroticism          0.297468\n",
       "Extraversion         0.297468\n",
       "Openness             0.772152\n",
       "Agreeableness        0.772152\n",
       "Conscientiousness    0.297468\n",
       "NS_total             0.297468\n",
       "BIS_total            0.297468\n",
       "BIS.5                0.297468\n",
       "BAS_D                0.297468\n",
       "BAS_FS               0.297468\n",
       "BAS_RR               0.297468\n",
       "HAP_actual           0.297468\n",
       "P_actual             0.297468\n",
       "LAP_actual           0.297468\n",
       "LA_actual            0.297468\n",
       "LAN_actual           0.297468\n",
       "N_actual             0.297468\n",
       "HAN_actual           0.297468\n",
       "HA_actual            0.297468\n",
       "HAP_ideal            0.297468\n",
       "P_ideal              0.297468\n",
       "LAP_ideal            0.297468\n",
       "LA_ideal             0.297468\n",
       "LAN_ideal            0.297468\n",
       "N_ideal              0.297468\n",
       "HAN_ideal            0.297468\n",
       "HA_ideal             0.297468\n",
       "Education            0.000000\n",
       "Ethnicity            0.000000\n",
       "Sex                  0.000000\n",
       "Marital_Status       0.000000\n",
       "Children             0.000000\n",
       "Household_income     0.000000\n",
       "Religion             0.000000\n",
       "Age                  0.000000\n",
       "Medications          0.000000\n",
       "BMI                  0.158228\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing data detection\n",
    "survey_df.isna().sum()/survey_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>SBQ</th>\n",
       "      <th>FTP</th>\n",
       "      <th>SWLS</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>NS_total</th>\n",
       "      <th>...</th>\n",
       "      <th>Education</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Children</th>\n",
       "      <th>Household_income</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Age</th>\n",
       "      <th>Medications</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$10,000-$19,999</td>\n",
       "      <td>Buddhism</td>\n",
       "      <td>32.0</td>\n",
       "      <td>None</td>\n",
       "      <td>23.725936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>White/Pacific Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$10,000-$19,999</td>\n",
       "      <td>Questionable</td>\n",
       "      <td>28.0</td>\n",
       "      <td>None</td>\n",
       "      <td>30.221958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1008</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>2.0</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>Judiasm</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Aciphex</td>\n",
       "      <td>31.306605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1009</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>$150,000 or more</td>\n",
       "      <td>Judiasm</td>\n",
       "      <td>58.0</td>\n",
       "      <td>None</td>\n",
       "      <td>28.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1014</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Married</td>\n",
       "      <td>3.0</td>\n",
       "      <td>$120,000-$129,999</td>\n",
       "      <td>Christianity</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Lipitor, Diovan, 81mg Aspirin</td>\n",
       "      <td>31.256942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject   SBQ  FTP  SWLS  Neuroticism  Extraversion  Openness  \\\n",
       "0    1002  55.0  6.8  20.0         26.0          48.0      47.0   \n",
       "1    1004  45.0  5.3  25.0         28.0          48.0      46.0   \n",
       "2    1008  57.0  5.0  24.0         28.0          47.0      28.0   \n",
       "3    1009  53.0  5.0  22.0         26.0          45.0      42.0   \n",
       "4    1014  55.0  3.7  25.0         26.0          36.0      41.0   \n",
       "\n",
       "   Agreeableness  Conscientiousness  NS_total  ...  Education  \\\n",
       "0           48.0               46.0      16.0  ...         14   \n",
       "1           49.0               49.0      18.0  ...         14   \n",
       "2           50.0               48.0      11.0  ...         16   \n",
       "3           43.0               48.0       7.0  ...         22   \n",
       "4           42.0               49.0       9.0  ...         18   \n",
       "\n",
       "                Ethnicity     Sex  Marital_Status  Children  \\\n",
       "0                   White  Female          Single       0.0   \n",
       "1  White/Pacific Islander    Male          Single       0.0   \n",
       "2                   White    Male         Married       2.0   \n",
       "3                   White    Male         Married       0.0   \n",
       "4                   White  Female         Married       3.0   \n",
       "\n",
       "    Household_income      Religion   Age                    Medications  \\\n",
       "0    $10,000-$19,999      Buddhism  32.0                           None   \n",
       "1    $10,000-$19,999  Questionable  28.0                           None   \n",
       "2   $150,000 or more       Judiasm  46.0                        Aciphex   \n",
       "3   $150,000 or more       Judiasm  58.0                           None   \n",
       "4  $120,000-$129,999  Christianity  68.0  Lipitor, Diovan, 81mg Aspirin   \n",
       "\n",
       "         BMI  \n",
       "0  23.725936  \n",
       "1  30.221958  \n",
       "2  31.306605  \n",
       "3  28.408163  \n",
       "4  31.256942  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject               object\n",
       "SBQ                  float64\n",
       "FTP                  float64\n",
       "SWLS                 float64\n",
       "Neuroticism          float64\n",
       "Extraversion         float64\n",
       "Openness             float64\n",
       "Agreeableness        float64\n",
       "Conscientiousness    float64\n",
       "NS_total             float64\n",
       "BIS_total            float64\n",
       "BIS.5                float64\n",
       "BAS_D                float64\n",
       "BAS_FS               float64\n",
       "BAS_RR               float64\n",
       "HAP_actual           float64\n",
       "P_actual             float64\n",
       "LAP_actual           float64\n",
       "LA_actual            float64\n",
       "LAN_actual           float64\n",
       "N_actual             float64\n",
       "HAN_actual           float64\n",
       "HA_actual            float64\n",
       "HAP_ideal            float64\n",
       "P_ideal              float64\n",
       "LAP_ideal            float64\n",
       "LA_ideal             float64\n",
       "LAN_ideal            float64\n",
       "N_ideal              float64\n",
       "HAN_ideal            float64\n",
       "HA_ideal             float64\n",
       "Education             object\n",
       "Ethnicity             object\n",
       "Sex                   object\n",
       "Marital_Status        object\n",
       "Children             float64\n",
       "Household_income      object\n",
       "Religion              object\n",
       "Age                  float64\n",
       "Medications           object\n",
       "BMI                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Fix ID inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix subject ID inconsistant issue, only run once\n",
    "exp['subject'] = exp['subject'].str.replace('DND', 'DND1', regex=False)\n",
    "survey_df['Subject'] = survey_df['Subject'].str.replace('DND', 'DND1', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Time window for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 30 mins prior time point\n",
    "exp['start_survey_5m_ahead'] = exp['start_survey'] - datetime.timedelta(minutes=5)\n",
    "exp['start_survey_10m_ahead'] = exp['start_survey'] - datetime.timedelta(minutes=10)\n",
    "exp['start_survey_30m_ahead'] = exp['start_survey'] - datetime.timedelta(minutes=30)\n",
    "exp['start_survey_1h_ahead'] = exp['start_survey'] - datetime.timedelta(minutes=60)\n",
    "exp['start_survey_3h_ahead'] = exp['start_survey'] - datetime.timedelta(hours=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Step related feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps related features:\n",
    "* Statistics: max, min, mean, std\n",
    "* Move Rate: The # of minutes with step > 0 / total minutes\n",
    "* Active Rate: The # of minutes with step > 10 / total minutes\n",
    "* Very Active Rate: The # of minutes with step > 20 / total minutes\n",
    "* Running Rate: The # of minutes with step > 30 / total minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_feature_gen(df):\n",
    "    if df.shape[0] == 0:\n",
    "        return [None,None,None,None,None,None,None,None,None]\n",
    "    else:\n",
    "        max_step = df['VALUE'].max()\n",
    "        min_step = df['VALUE'].min()\n",
    "        mean = df['VALUE'].mean()\n",
    "        var = df['VALUE'].var()\n",
    "        median = df['VALUE'].median()\n",
    "        move_rate = df[df['VALUE'] > 0].shape[0]/df.shape[0]\n",
    "        active_rate = df[df['VALUE'] > 10].shape[0]/df.shape[0]\n",
    "        very_active_rate = df[df['VALUE'] > 20].shape[0]/df.shape[0]\n",
    "        running_rate = df[df['VALUE'] > 30].shape[0]/df.shape[0]\n",
    "        return [max_step, min_step, mean, var, median, move_rate, active_rate, very_active_rate, running_rate]\n",
    "\n",
    "def gen_step_features_by_id(subject_id, index, row, step_by_id):\n",
    "    start_3h_time = row['start_survey_3h_ahead']\n",
    "    start_1h_time = row['start_survey_1h_ahead']\n",
    "    start_30m_time = row['start_survey_30m_ahead']\n",
    "    start_10m_time = row['start_survey_10m_ahead']\n",
    "    start_5m_time = row['start_survey_5m_ahead']\n",
    "    end_time = row['start_survey']\n",
    "    df_before_exp = step_by_id[step_by_id['datetime'] <= end_time]\n",
    "    df_3h = df_before_exp[df_before_exp['datetime'] >= start_3h_time]\n",
    "    df_1h = df_before_exp[df_before_exp['datetime'] >= start_1h_time]\n",
    "    df_30m = df_before_exp[df_before_exp['datetime'] >= start_30m_time]\n",
    "    df_10m = df_before_exp[df_before_exp['datetime'] >= start_10m_time]\n",
    "    df_5m = df_before_exp[df_before_exp['datetime'] >= start_5m_time]\n",
    "    # Generate features\n",
    "    step_features_3h = step_feature_gen(df_3h)\n",
    "    step_features_1h = step_feature_gen(df_1h)\n",
    "    step_features_30m = step_feature_gen(df_30m)\n",
    "    step_features_10m = step_feature_gen(df_10m)\n",
    "    step_features_5m = step_feature_gen(df_5m)\n",
    "    prev_max_step = df_before_exp['VALUE'].max()\n",
    "    prev_min_step = df_before_exp['VALUE'].min()\n",
    "    prev_med_step = df_before_exp['VALUE'].median()\n",
    "    return [index, subject_id, prev_max_step, prev_min_step, prev_med_step] \\\n",
    "            + step_features_3h + step_features_1h + step_features_30m + step_features_10m + step_features_5m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1. Get subject id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DND1058'}\n",
      "{'DND1033', '1079', '1097'}\n"
     ]
    }
   ],
   "source": [
    "steps_ids = np.unique(steps['ID'].values)\n",
    "exp_ids = np.unique(exp.subject.values)\n",
    "# Detect subject without experience sampling data\n",
    "print(set(steps_ids) - set(exp_ids))\n",
    "# Detect subject without step data\n",
    "print(set(exp_ids) - set(steps_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step2. Calculate step features for all subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107\r"
     ]
    }
   ],
   "source": [
    "# Get All Unique IDs, remove subject without step data. (we could not construct step features for them.)\n",
    "exp_ids = np.unique(exp.subject.values)\n",
    "exp_id_1 = np.in1d(exp_ids, 'DND1033').nonzero()[0]\n",
    "exp_id_2 = np.in1d(exp_ids, '1079').nonzero()[0]\n",
    "exp_id_3 = np.in1d(exp_ids, '1097').nonzero()[0]\n",
    "\n",
    "exp_ids = np.delete(exp_ids, [exp_id_1,exp_id_2,exp_id_3])\n",
    "    \n",
    "# Result stores here\n",
    "step_features = []\n",
    "# Count for progress\n",
    "count = 0\n",
    "# Iterate each id, decrease redundant computation\n",
    "for exp_id in exp_ids:\n",
    "    # Progress output\n",
    "    count += 1\n",
    "    b = str(count) + '/'+ str(len(exp_ids))\n",
    "    print (b, end=\"\\r\")\n",
    "    # Get subject_id\n",
    "    subject_id = exp_id\n",
    "    # Extract exp dataframe by subject_id\n",
    "    exp_by_id = exp[exp['subject'].astype(str) == subject_id]\n",
    "    # Extract heart rate dataframe by subject_id\n",
    "    step_by_id = steps[steps['ID'].astype(str) == subject_id]\n",
    "    # Generate features for each experience sampling of each subject\n",
    "    for index, row in exp_by_id.iterrows():\n",
    "        feature_by_row = gen_step_features_by_id(exp_id, index, row, step_by_id)\n",
    "        step_features.append(feature_by_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3. Convert results to dataframe, and drop NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps_features = pd.DataFrame(steps_features.dropna())\n",
    "steps_features_colnames = ['index', 'subject_id', 'step_max', 'step_min', 'step_median',\n",
    "                'steps_max_3h','steps_min_3h','steps_mean_3h', 'steps_var_3h', 'steps_median_3h', 'move_rate_3h', 'active_rate_3h', 'very_active_rate_3h', 'running_rate_3h',\n",
    "                'steps_max_1h','steps_min_1h','steps_mean_1h', 'steps_var_1h', 'steps_median_1h', 'move_rate_1h', 'active_rate_1h', 'very_active_rate_1h', 'running_rate_1h',\n",
    "                'steps_max_30m','steps_min_30m','steps_mean_30m', 'steps_var_30m', 'steps_median_30m', 'move_rate_30m', 'active_rate_30m', 'very_active_rate_30m', 'running_rate_30m',\n",
    "                'steps_max_10m','steps_min_10m','steps_mean_10m', 'steps_var_10m', 'steps_median_10m', 'move_rate_10m', 'active_rate_10m', 'very_active_rate_10m', 'running_rate_10m',\n",
    "                'steps_max_5m','steps_min_5m','steps_mean_5m', 'steps_var_5m', 'steps_median_5m', 'move_rate_5m', 'active_rate_5m', 'very_active_rate_5m', 'running_rate_5m']\n",
    "step_features_df = pd.DataFrame(step_features)\n",
    "step_features_df.columns = steps_features_colnames\n",
    "# Drop NA\n",
    "step_features_cl = step_features_df.dropna()\n",
    "step_features_cl.to_csv('step_features_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Heart Rate related features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heart Rate related features:\n",
    "* Statistics: max, min, mean, std\n",
    "* Resting Rate: The # of minutes with HR < 30 percentile heart rate > 0 / total minutes\n",
    "* Moderate Rate: The # of minutes with HR > 50 percentile heart rate > 0 / total minutes\n",
    "* Very Active Rate: The # of minutes with HR > 80 percentile heart rate > 0 / total minutes\n",
    "* SDNN: Standard deviation of heartbeat intervals\n",
    "* pHR2: Percentage of the difference between ajacent HR greater than 2\n",
    "* rMSSD: Root of mean squared HR change\n",
    "* Highest HR\n",
    "* Lowest HR\n",
    "* l_h: Lowest HR / Highest HR\n",
    "* CR: Highest HR / Highest HR so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr_feature_gen(df, rest_thred, moderate_thred, active_thred, hr_max):\n",
    "    if df.shape[0] == 0:\n",
    "        return [None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
    "    else:\n",
    "        mean = df['VALUE'].mean()\n",
    "        var = df['VALUE'].var()\n",
    "        std = df['VALUE'].std()\n",
    "        median = df['VALUE'].median()\n",
    "        rest_rate = df[df['VALUE'] <= rest_thred].shape[0]/df.shape[0]\n",
    "        moderate_rate = df[df['VALUE'] > moderate_thred].shape[0]/df.shape[0]\n",
    "        very_active_rate = df[df['VALUE'] > active_thred].shape[0]/df.shape[0]\n",
    "        \n",
    "        hr_interval_all = np.array([])\n",
    "        for index, row in df.iterrows():\n",
    "            hr_by_min = row['VALUE']\n",
    "            hr_interval_min = np.full((1, hr_by_min), 1/hr_by_min)[0]\n",
    "            hr_interval_all = np.concatenate([hr_interval_min, hr_interval_all])\n",
    "        # SDNN - Standard deviation of heartbeat intervals\n",
    "        SDNN = hr_interval_all.std()\n",
    "        # pHR2 - percentage of the difference between ajacent HR greater than 2\n",
    "        hr_seq = df['VALUE'].values\n",
    "        hr_diff = abs(hr_seq[:-1] - hr_seq[1:])\n",
    "        # rMSSD\n",
    "        if len(hr_diff) == 0:\n",
    "            pHR2 = None\n",
    "            rMSSD = None\n",
    "        else:\n",
    "            pHR2 = sum(hr_diff > 2)/len(hr_diff)\n",
    "            rMSSD = np.sqrt(sum(hr_diff**2)/len(hr_diff))\n",
    "            # Lowest heart rate\n",
    "        low_hr = df['VALUE'].min()\n",
    "        # Highest heart rate\n",
    "        high_hr = df['VALUE'].max()\n",
    "        # LR/HR\n",
    "        if high_hr == 0:\n",
    "            l_h = None\n",
    "        else:\n",
    "            l_h = low_hr/high_hr\n",
    "        # CR - high_hr/hr_max_of_all_time\n",
    "        if hr_max == 0:\n",
    "            CR = None\n",
    "        else:\n",
    "            CR = high_hr/hr_max\n",
    "        \n",
    "        return [SDNN, pHR2, rMSSD, low_hr, high_hr, l_h, CR, mean, var, std, median, rest_rate, moderate_rate, very_active_rate]\n",
    "\n",
    "def gen_hr_features_by_id(subject_id, index, row, hr_by_id):\n",
    "    start_3h_time = row['start_survey_3h_ahead']\n",
    "    start_1h_time = row['start_survey_1h_ahead']\n",
    "    start_30m_time = row['start_survey_30m_ahead']\n",
    "    start_10m_time = row['start_survey_10m_ahead']\n",
    "    start_5m_time = row['start_survey_5m_ahead']\n",
    "    end_time = row['start_survey']\n",
    "    \n",
    "    df_before_exp = hr_by_id[hr_by_id['datetime'] <= end_time]\n",
    "    hr_percentile = df_before_exp['VALUE'].quantile([0, .3, .5, .8, 1]).values\n",
    "    rest_thred = hr_percentile[1]\n",
    "    moderate_thred = hr_percentile[2]\n",
    "    active_thred = hr_percentile[3]\n",
    "\n",
    "    df_3h = df_before_exp[df_before_exp['datetime'] >= start_3h_time]\n",
    "    df_1h = df_before_exp[df_before_exp['datetime'] >= start_1h_time]\n",
    "    df_30m = df_before_exp[df_before_exp['datetime'] >= start_30m_time]\n",
    "    df_10m = df_before_exp[df_before_exp['datetime'] >= start_10m_time]\n",
    "    df_5m = df_before_exp[df_before_exp['datetime'] >= start_5m_time]\n",
    "    # All time features\n",
    "    hr_max = df_before_exp['VALUE'].max()\n",
    "    hr_min = df_before_exp['VALUE'].min()\n",
    "    hr_med = df_before_exp['VALUE'].median()\n",
    "    # Generate features\n",
    "    hr_features_3h = hr_feature_gen(df_3h, rest_thred, moderate_thred, active_thred, hr_max)\n",
    "    hr_features_1h = hr_feature_gen(df_1h, rest_thred, moderate_thred, active_thred, hr_max)\n",
    "    hr_features_30m = hr_feature_gen(df_30m, rest_thred, moderate_thred, active_thred, hr_max)\n",
    "    hr_features_10m = hr_feature_gen(df_10m, rest_thred, moderate_thred, active_thred, hr_max)\n",
    "    hr_features_5m = hr_feature_gen(df_5m, rest_thred, moderate_thred, active_thred, hr_max)\n",
    "    \n",
    "    return [index, subject_id, hr_max, hr_min, hr_med] + [hr_percentile[0],hr_percentile[1],hr_percentile[2],hr_percentile[3],hr_percentile[4]]\\\n",
    "            + hr_features_3h + hr_features_1h + hr_features_30m + hr_features_10m + hr_features_5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DND1058'}\n",
      "{'DND1033'}\n"
     ]
    }
   ],
   "source": [
    "# Detect ids in hr but not in exp\n",
    "hr_ids = np.unique(hr['ID'].values)\n",
    "exp_ids = np.unique(exp.subject.values)\n",
    "print(set(hr_ids) - set(exp_ids))\n",
    "# Detect ids in exp but not in hr\n",
    "print(set(exp_ids) - set(hr_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1. Get Subject ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get All Unique IDs\n",
    "exp_ids = np.unique(exp.subject.values)\n",
    "exp_id_1 = np.in1d(exp_ids, 'DND1033').nonzero()[0]\n",
    "exp_ids = np.delete(exp_ids, exp_id_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step2. Calculate features by subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109\r"
     ]
    }
   ],
   "source": [
    "# Count for progress\n",
    "count = 0\n",
    "# Result stores here\n",
    "hr_features = []\n",
    "# Iterate each id, decrease redundant computation\n",
    "for exp_id in exp_ids:\n",
    "    # Progress output\n",
    "    count += 1\n",
    "    b = str(count) + '/'+ str(len(exp_ids))\n",
    "    print (b, end=\"\\r\")\n",
    "    # Get subject_id\n",
    "    subject_id = exp_id\n",
    "    # Extract exp dataframe by subject_id\n",
    "    exp_by_id = exp[exp['subject'].astype(str) == subject_id]\n",
    "    # Extract heart rate dataframe by subject_id\n",
    "    hr_by_id = hr[(hr['ID'].astype(str) == subject_id)]\n",
    "    # Generate features for each experience sampling of each subject\n",
    "    for index, row in exp_by_id.iterrows():\n",
    "        feature_by_row = gen_hr_features_by_id(exp_id, index, row, hr_by_id)\n",
    "        hr_features.append(feature_by_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3. Convert results to dataframe, and drop NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_features_colnames = ['index', 'subject_id', 'hr_max', 'hr_min', 'hr_med', 'hr_0','hr_0.3','hr_0.5','hr_0.8','hr_1',\n",
    "                         'SDNN_3h', 'pHR2_3h', 'rMSSD_3h', 'low_hr_3h', 'high_hr_3h', 'l_h_3h', 'CR_3h',\n",
    "                         'hr_mean_3h', 'hr_var_3h', 'hr_std_3h', 'hr_median_3h', 'hr_rest_rate_3h', 'hr_moderate_rate_3h', 'hr_very_active_rate_3h',\n",
    "                         'SDNN_1h', 'pHR2_1h', 'rMSSD_1h', 'low_hr_1h', 'high_hr_1h', 'l_h_1h', 'CR_1h',\n",
    "                         'hr_mean_1h', 'hr_var_1h', 'hr_std_1h', 'hr_median_1h', 'hr_rest_rate_1h', 'hr_moderate_rate_1h', 'hr_very_active_rate_1h',\n",
    "                         'SDNN_30m', 'pHR2_30m', 'rMSSD_30m', 'low_hr_30m', 'high_hr_30m', 'l_h_30m', 'CR_30m',\n",
    "                         'hr_mean_30m', 'hr_var_30m', 'hr_std_30m', 'hr_median_30m', 'hr_rest_rate_30m', 'hr_moderate_rate_30m', 'hr_very_active_rate_30m',\n",
    "                         'SDNN_10m', 'pHR2_10m', 'rMSSD_10m', 'low_hr_10m', 'high_hr_10m', 'l_h_10m', 'CR_10m',\n",
    "                         'hr_mean_10m', 'hr_var_10m', 'hr_std_10m', 'hr_median_10m', 'hr_rest_rate_10m', 'hr_moderate_rate_10m', 'hr_very_active_rate_10m',\n",
    "                         'SDNN_5m', 'pHR2_5m', 'rMSSD_5m', 'low_hr_5m', 'high_hr_5m', 'l_h_5m', 'CR_5m',\n",
    "                         'hr_mean_5m', 'hr_var_5m', 'hr_std_5m', 'hr_median_5m', 'hr_rest_rate_5m', 'hr_moderate_rate_5m', 'hr_very_active_rate_5m']\n",
    "hr_features_df = pd.DataFrame(hr_features)\n",
    "hr_features_df.columns = hr_features_colnames\n",
    "# Drop NA\n",
    "hr_features_cl = hr_features_df.dropna()\n",
    "# Export\n",
    "hr_features_cl.to_csv('hr_features_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index_x</th>\n",
       "      <td>0.218618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id_x</th>\n",
       "      <td>0.218618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr_mean_3h</th>\n",
       "      <td>0.218618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr_var_3h</th>\n",
       "      <td>0.218618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr_std_3h</th>\n",
       "      <td>0.218618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survey_date</th>\n",
       "      <td>0.002595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_survey_10m_ahead</th>\n",
       "      <td>0.002595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_survey_30m_ahead</th>\n",
       "      <td>0.002595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_survey_1h_ahead</th>\n",
       "      <td>0.002595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_survey_3h_ahead</th>\n",
       "      <td>0.002595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0\n",
       "index_x                 0.218618\n",
       "subject_id_x            0.218618\n",
       "hr_mean_3h              0.218618\n",
       "hr_var_3h               0.218618\n",
       "hr_std_3h               0.218618\n",
       "...                          ...\n",
       "survey_date             0.002595\n",
       "start_survey_10m_ahead  0.002595\n",
       "start_survey_30m_ahead  0.002595\n",
       "start_survey_1h_ahead   0.002595\n",
       "start_survey_3h_ahead   0.002595\n",
       "\n",
       "[81 rows x 1 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(exp_steps_hr.isna().sum() / exp_steps_hr.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index for merging\n",
    "step_features_cl = step_features_cl.set_index('index')\n",
    "hr_features_cl = hr_features_cl.set_index('index')\n",
    "# Convert id column data type for merging\n",
    "exp_steps_hr['subject'] = exp_steps_hr['subject'].astype(str)\n",
    "sleep['ID'] = sleep['ID'].astype(str)\n",
    "# Create 'survey_date' in exp for merging with sleep\n",
    "exp['start_survey'] = pd.to_datetime(exp['start_survey'])\n",
    "exp['survey_date'] = pd.to_datetime(exp['start_survey'].dt.date)\n",
    "# Add 'survey_date' to sleep data\n",
    "sleep['Date'] = pd.to_datetime(sleep['Date'])\n",
    "sleep['Date'] = pd.to_datetime(sleep['Date'].dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge design matrix progressively\n",
    "exp_steps = pd.merge(exp, step_features_cl, how='left', left_index=True, right_index=True)\n",
    "exp_steps_hr = pd.merge(exp_steps, hr_features_cl, how='left', left_index=True, right_index=True)\n",
    "exp_steps_hr_sleep = pd.merge(exp_steps_hr, sleep, how='left', left_on=['subject','survey_date'], right_on=['ID','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_steps_hr_sleep.to_csv('exp_steps_hr_sleep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_steps_hr_sleep_survey = pd.merge(exp_steps_hr_sleep, survey_df, how='left', left_on=['subject'], right_on=['Subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add survey hour as a feature\n",
    "exp_steps_hr_sleep_survey['survey_hour'] = exp_steps_hr_sleep_survey.start_survey.dt.hour\n",
    "# Export data\n",
    "exp_steps_hr_sleep_survey.to_csv('exp_steps_hr_sleep_survey.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data detection\n",
    "missing_df = exp_steps_hr_sleep_survey.isna().sum()/exp_steps_hr_sleep_survey.shape[0]\n",
    "# Export missing data\n",
    "pd.DataFrame(missing_df).to_csv('missingness.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
