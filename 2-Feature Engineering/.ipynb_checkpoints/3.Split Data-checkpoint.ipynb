{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, StratifiedKFold\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = pd.read_csv('../data/processed/exp.csv', index_col=0)\n",
    "\n",
    "label_cols = ['la_p','ha_p','ha_n','la_n','la','ha','p','n','max_p','max_n','valence_p','valence_n','valence_reg','valence', 'subject']\n",
    "feature_cols = set(exp.columns.values) - set(label_cols)\n",
    "feature_cols = list(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Split data by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize Subjects with weighted probability\n",
    "sub_id_prob = exp['subject'].value_counts()/exp.shape[0]\n",
    "sub_id = sub_id_prob.index.values\n",
    "val_subjects = np.random.choice(sub_id,15,p=sub_id_prob)\n",
    "\n",
    "# Split Validation Set\n",
    "val_data = exp[exp['subject'].isin(val_subjects)]\n",
    "X_val = val_data[feature_cols]\n",
    "y_val = val_data[['max_p','max_n','valence_p','valence_n','valence_reg','valence', 'subject']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test dataset\n",
    "exp_train_test = exp[~exp['subject'].isin(val_subjects)]\n",
    "# Remove Validation Set from Dataframe\n",
    "exp_train_test = exp[~exp['subject'].isin(val_subjects)]\n",
    "# Split Training and Test set\n",
    "X = exp_train_test[feature_cols]\n",
    "y = exp_train_test[['max_p','max_n','valence_p','valence_n','valence_reg','valence', 'subject']]\n",
    "group = exp_train_test['subject'].values\n",
    "gkf_modeling = list(GroupKFold(n_splits=5).split(X,y,group))\n",
    "X_train = X.iloc[gkf_modeling[0][0],]\n",
    "X_test = X.iloc[gkf_modeling[0][1],]\n",
    "y_train = y.iloc[gkf_modeling[0][0],]\n",
    "y_test = y.iloc[gkf_modeling[0][1],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export result\n",
    "X_val.to_csv('../data/processed/new_user/X_val_group.csv', index=False)\n",
    "y_val.to_csv('../data/processed/new_user/y_val_group.csv', index=False)\n",
    "X_test.to_csv('../data/processed/new_user/X_test_group.csv', index=False)\n",
    "y_test.to_csv('../data/processed/new_user/y_test_group.csv', index=False)\n",
    "X_train.to_csv('../data/processed/new_user/X_train_group.csv', index=False)\n",
    "y_train.to_csv('../data/processed/new_user/y_train_group.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((341, 170), (309, 170), (1223, 170))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, X_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Stratifies Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and labels\n",
    "X_stratified = exp[feature_cols]\n",
    "y_stratified = exp[['max_p','max_n','valence_p','valence_n','valence_reg','valence','subject']]\n",
    "# ID for stratification\n",
    "group_stratified = exp['subject']\n",
    "# Split validation set\n",
    "X_stratified_train_test, X_stratified_val, y_stratified_train_test, y_stratified_val = train_test_split(X_stratified, y_stratified, test_size=0.2, stratify=group_stratified)\n",
    "# Split training/test set\n",
    "group_stratified_2 = exp.iloc[X_stratified_train_test.index.values]['subject']\n",
    "X_stratified_train, X_stratified_test, y_stratified_train, y_stratified_test = train_test_split(X_stratified_train_test, y_stratified_train_test, test_size=0.25, stratify=group_stratified_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export result\n",
    "X_stratified_val.to_csv('../data/processed/cur_user/X_val_stratify.csv', index=False)\n",
    "y_stratified_val.to_csv('../data/processed/cur_user/y_val_stratify.csv', index=False)\n",
    "X_stratified_test.to_csv('../data/processed/cur_user/X_test_stratify.csv', index=False)\n",
    "y_stratified_test.to_csv('../data/processed/cur_user/y_test_stratify.csv', index=False)\n",
    "X_stratified_train.to_csv('../data/processed/cur_user/X_train_stratify.csv', index=False)\n",
    "y_stratified_train.to_csv('../data/processed/cur_user/y_train_stratify.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Upsample Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_data(X, y):\n",
    "    # concatenate our training data back together\n",
    "    data_to_sample = pd.concat([X, y], axis=1)\n",
    "    # separate minority and majority classes\n",
    "    unhappy = data_to_sample[data_to_sample['valence']==1]\n",
    "    happy = data_to_sample[data_to_sample['valence']==0]\n",
    "\n",
    "\n",
    "    # upsample minority\n",
    "    unhappy_upsampled = resample(unhappy,\n",
    "                        replace=True, # sample with replacement\n",
    "                        n_samples=len(happy), # match number in majority class\n",
    "                        random_state=27) # reproducible results\n",
    "\n",
    "    # combine majority and upsampled minority\n",
    "    upsampled = pd.concat([happy, unhappy_upsampled])\n",
    "\n",
    "    # Split train and test\n",
    "    y_upsample = upsampled[['max_p','max_n','valence_p','valence_n','valence_reg','valence', 'subject']]\n",
    "    X_upsample = upsampled.drop(['max_p','max_n','valence_p','valence_n','valence_reg','valence', 'subject'], axis=1)\n",
    "\n",
    "    return X_upsample, y_upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_up_train, y_up_train = upsample_data(X_train, y_train)\n",
    "X_stratified_up_train, y_stratified_up_train = upsample_data(X_stratified_train, y_stratified_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_up_train.to_csv('../data/processed/new_user/X_train_group_up.csv', index=False)\n",
    "y_up_train.to_csv('../data/processed/new_user/y_train_group_up.csv', index=False)\n",
    "X_stratified_up_train.to_csv('../data/processed/cur_user/X_train_stratify_up.csv', index=False)\n",
    "y_stratified_up_train.to_csv('../data/processed/cur_user/y_train_stratify_up.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
